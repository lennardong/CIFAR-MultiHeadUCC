{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T16:29:55.991698Z",
     "start_time": "2023-11-11T16:29:54.171287Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from typing import Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721089ce35828f",
   "metadata": {},
   "source": [
    "# Test Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "349fa8ef1836543a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T07:46:58.906693Z",
     "start_time": "2023-11-12T07:46:55.188946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([32, 300, 32, 32, 3])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from dataloader import create_dataloaders\n",
    "from torchvision.transforms import functional as TF\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "PATH = '../data/Splitted CIFAR10.npz'\n",
    "\n",
    "# Inits\n",
    "transforms = {\n",
    "    'random_horizontal_flip': lambda img: TF.hflip(img) if random.random() > 0.5 else img,\n",
    "    'random_vertical_flip': lambda img: TF.vflip(img) if random.random() > 0.5 else img,\n",
    "    'color_jitter': lambda img: TF.adjust_brightness(img, brightness_factor=random.uniform(0.8, 1.2)),\n",
    "    'normalize': lambda img: TF.normalize(img, mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    npz_path_: str = '../data/Splitted CIFAR10.npz'\n",
    "    lower_ucc: int = 2\n",
    "    upper_ucc: int = 4\n",
    "    bag_size: int = 300\n",
    "    bag_fraction: float = 0.3\n",
    "    batch_size: int = 32\n",
    "    transform: Dict = None\n",
    "\n",
    "# TEST \n",
    "\n",
    "data_config_test = DataConfig()\n",
    "dataloaders = create_dataloaders(**data_config_test.__dict__)\n",
    "\n",
    "# Testing the dataloaders\n",
    "for images, labels in dataloaders['train']:\n",
    "    print(f'Images batch shape: {images.shape}')\n",
    "    print(f'Labels batch shape: {labels.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91c4c3b06992c5",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df8a29dd2fae088",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T07:45:35.177220Z",
     "start_time": "2023-11-12T07:45:35.121116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Data: torch.Size([2, 5, 3, 32, 32])\n",
      "Logits shape: torch.Size([2, 10])\n",
      "Decoded images shape: torch.Size([2, 5, 3, 32, 32])\n",
      "UCCModel(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (kde_embeddings): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4096, out_features=220, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=220, out_features=110, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (mlp_classifier): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=1100, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import UCCModel\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    num_bins: int = 10\n",
    "    sigma : float = 0.1\n",
    "    dropout_rate: float = 0.1\n",
    "    num_classes: int = 10\n",
    "    embedding_size: int = 110\n",
    "    fc2_size: int = 512\n",
    "\n",
    "# Init    \n",
    "model_config_test = ModelConfig()\n",
    "model = UCCModel(**model_config_test.__dict__)\n",
    "\n",
    "# Test\n",
    "\n",
    "# Mock data\n",
    "batch_size, num_instances, channels, height, width = 2, 5, 3, 32, 32\n",
    "random_data = torch.randn((batch_size, num_instances, channels, height, width))\n",
    "\n",
    "# Forward pass through the model\n",
    "logits, decoded_imgs = model(random_data)\n",
    "\n",
    "# Outputs\n",
    "print(\"Random Data:\", random_data.shape)\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Decoded images shape:\", decoded_imgs.shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7574762f437ac",
   "metadata": {},
   "source": [
    "# Test Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c22b940651daba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T07:45:40.034256Z",
     "start_time": "2023-11-12T07:45:40.022880Z"
    }
   },
   "outputs": [],
   "source": [
    "from train import Trainer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    model: nn.Module\n",
    "    optimizer: torch.optim.Optimizer\n",
    "    train_loader: DataLoader\n",
    "    val_loader: DataLoader\n",
    "    model_name: str\n",
    "    total_steps: int = 10_000\n",
    "    eval_interval: int = 100\n",
    "    ucc_loss_weight: float = 0.5\n",
    "    model_dir: str = \"./models\"\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce01dda515de70c",
   "metadata": {},
   "source": [
    "# Test Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2335da63e4a1b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T16:31:37.667710Z",
     "start_time": "2023-11-11T16:30:41.324754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "mps\n",
      "##########################\n",
      "# Starting Training...\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      "Training Progress:   0%|          | 0/100 [00:18<?, ?it/s, Train Loss: 1.6447, Val Loss: 1.3151, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:   5%|▌         | 5/100 [00:18<05:52,  3.71s/it, Train Loss: 1.6447, Val Loss: 1.3151, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:   5%|▌         | 5/100 [00:22<05:52,  3.71s/it, Train Loss: 1.2964, Val Loss: 1.2648, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  10%|█         | 10/100 [00:22<03:02,  2.02s/it, Train Loss: 1.2964, Val Loss: 1.2648, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  10%|█         | 10/100 [00:24<03:02,  2.02s/it, Train Loss: 1.2510, Val Loss: 1.2371, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  15%|█▌        | 15/100 [00:24<01:46,  1.25s/it, Train Loss: 1.2510, Val Loss: 1.2371, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  15%|█▌        | 15/100 [00:26<01:46,  1.25s/it, Train Loss: 1.2304, Val Loss: 1.2076, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  20%|██        | 20/100 [00:26<01:11,  1.12it/s, Train Loss: 1.2304, Val Loss: 1.2076, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  20%|██        | 20/100 [00:27<01:11,  1.12it/s, Train Loss: 1.1308, Val Loss: 1.1766, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  25%|██▌       | 25/100 [00:27<00:51,  1.44it/s, Train Loss: 1.1308, Val Loss: 1.1766, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  25%|██▌       | 25/100 [00:29<00:51,  1.44it/s, Train Loss: 1.1712, Val Loss: 1.1644, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  30%|███       | 30/100 [00:29<00:40,  1.74it/s, Train Loss: 1.1712, Val Loss: 1.1644, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  30%|███       | 30/100 [00:31<00:40,  1.74it/s, Train Loss: 1.2044, Val Loss: 1.1431, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  35%|███▌      | 35/100 [00:31<00:32,  2.00it/s, Train Loss: 1.2044, Val Loss: 1.1431, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  35%|███▌      | 35/100 [00:33<00:32,  2.00it/s, Train Loss: 1.1201, Val Loss: 1.1331, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  40%|████      | 40/100 [00:33<00:29,  2.02it/s, Train Loss: 1.1201, Val Loss: 1.1331, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  40%|████      | 40/100 [00:36<00:29,  2.02it/s, Train Loss: 1.0959, Val Loss: 1.1115, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  45%|████▌     | 45/100 [00:36<00:27,  1.97it/s, Train Loss: 1.0959, Val Loss: 1.1115, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  45%|████▌     | 45/100 [00:38<00:27,  1.97it/s, Train Loss: 1.0963, Val Loss: 1.1015, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  50%|█████     | 50/100 [00:38<00:22,  2.20it/s, Train Loss: 1.0963, Val Loss: 1.1015, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  50%|█████     | 50/100 [00:39<00:22,  2.20it/s, Train Loss: 1.0961, Val Loss: 1.0890, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  55%|█████▌    | 55/100 [00:39<00:18,  2.38it/s, Train Loss: 1.0961, Val Loss: 1.0890, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  55%|█████▌    | 55/100 [00:41<00:18,  2.38it/s, Train Loss: 1.0757, Val Loss: 1.0621, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  60%|██████    | 60/100 [00:41<00:16,  2.49it/s, Train Loss: 1.0757, Val Loss: 1.0621, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  60%|██████    | 60/100 [00:43<00:16,  2.49it/s, Train Loss: 1.0057, Val Loss: 1.0220, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  65%|██████▌   | 65/100 [00:43<00:13,  2.54it/s, Train Loss: 1.0057, Val Loss: 1.0220, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  65%|██████▌   | 65/100 [00:45<00:13,  2.54it/s, Train Loss: 1.0241, Val Loss: 0.9945, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  70%|███████   | 70/100 [00:45<00:11,  2.63it/s, Train Loss: 1.0241, Val Loss: 0.9945, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  70%|███████   | 70/100 [00:46<00:11,  2.63it/s, Train Loss: 0.9820, Val Loss: 0.9574, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  75%|███████▌  | 75/100 [00:46<00:09,  2.69it/s, Train Loss: 0.9820, Val Loss: 0.9574, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  75%|███████▌  | 75/100 [00:48<00:09,  2.69it/s, Train Loss: 0.9393, Val Loss: 0.9165, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  80%|████████  | 80/100 [00:48<00:07,  2.60it/s, Train Loss: 0.9393, Val Loss: 0.9165, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  80%|████████  | 80/100 [00:50<00:07,  2.60it/s, Train Loss: 0.9210, Val Loss: 0.8836, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  85%|████████▌ | 85/100 [00:50<00:05,  2.60it/s, Train Loss: 0.9210, Val Loss: 0.8836, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  85%|████████▌ | 85/100 [00:52<00:05,  2.60it/s, Train Loss: 0.9082, Val Loss: 0.8444, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  90%|█████████ | 90/100 [00:52<00:03,  2.70it/s, Train Loss: 0.9082, Val Loss: 0.8444, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  90%|█████████ | 90/100 [00:54<00:03,  2.70it/s, Train Loss: 0.8512, Val Loss: 0.8209, Val Acc: 0.4464]\u001B[A\n",
      "Training Progress:  95%|█████████▌| 95/100 [00:55<00:02,  1.72it/s, Train Loss: 0.8512, Val Loss: 0.8209, Val Acc: 0.4464]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Best validation accuracy: 0.4464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# CONFIGS\n",
    "############################################\n",
    "transforms = {\n",
    "    'random_horizontal_flip': lambda img: TF.hflip(img) if random.random() > 0.5 else img,\n",
    "    'random_vertical_flip': lambda img: TF.vflip(img) if random.random() > 0.5 else img,\n",
    "    'color_jitter': lambda img: TF.adjust_brightness(img, brightness_factor=random.uniform(0.8, 1.2)),\n",
    "    'normalize': lambda img: TF.normalize(img, mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "}\n",
    "\n",
    "DATA_CONFIG_1 = DataConfig(\n",
    "    npz_path_ = PATH,\n",
    "    lower_ucc = 1,\n",
    "    upper_ucc = 4,\n",
    "    bag_size = 20,\n",
    "    bag_fraction = 0.2,\n",
    "    batch_size = 10,\n",
    "    transform = transforms\n",
    ")\n",
    "\n",
    "MODEL_CONFIG_1 = ModelConfig(\n",
    "    num_bins = 10,\n",
    "    sigma = 0.1,\n",
    "    dropout_rate = 0.5,\n",
    "    num_classes = 5,\n",
    "    embedding_size = 50,\n",
    "    fc2_size = 512\n",
    ")\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "############################################\n",
    "# Instantiate Parts\n",
    "############################################\n",
    "\n",
    "# data\n",
    "dataloaders = create_dataloaders(**DATA_CONFIG_1.__dict__)\n",
    "\n",
    "# model\n",
    "model = UCCModel(**MODEL_CONFIG_1.__dict__)\n",
    "\n",
    "# Optimizer \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "############################################\n",
    "# Train\n",
    "############################################\n",
    "\n",
    "TRAIN_CONFIG_1 = TrainConfig(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    model_name=\"test_model\",\n",
    "    total_steps=100,\n",
    "    eval_interval=5,\n",
    "    ucc_loss_weight=0.5,\n",
    "    model_dir=\"../models\",\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    # device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "print(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "trainer = Trainer(**TRAIN_CONFIG_1.__dict__)\n",
    "\n",
    "# TEST\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1805de1ca60554",
   "metadata": {},
   "source": [
    "# Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594c044-9cf2-4984-8806-75bfc35e566d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-11T16:30:39.350222Z",
     "start_time": "2023-11-11T16:30:39.350090Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms = {\n",
    "    'random_horizontal_flip': lambda img: TF.hflip(img) if random.random() > 0.5 else img,\n",
    "    'random_vertical_flip': lambda img: TF.vflip(img) if random.random() > 0.5 else img,\n",
    "    'color_jitter': lambda img: TF.adjust_brightness(img, brightness_factor=random.uniform(0.8, 1.2)),\n",
    "    'normalize': lambda img: TF.normalize(img, mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "}\n",
    "\n",
    "DATA_CONFIG_1 = DataConfig(\n",
    "    npz_path_ = PATH,\n",
    "    lower_ucc = 1,\n",
    "    upper_ucc = 4,\n",
    "    bag_size = 100,\n",
    "    bag_fraction = 0.9,\n",
    "    batch_size = 10,\n",
    "    transform = transforms\n",
    ")\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "dataloaders = create_dataloaders(**DATA_CONFIG_1.__dict__)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1adb90272ef2c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T16:30:39.350954Z",
     "start_time": "2023-11-11T16:30:39.350545Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENT CARD \n",
    "\n",
    "Config A\n",
    "- num_bins: 10\n",
    "- sigma : 0.1\n",
    "- dropout_rate: 0.3\n",
    "- num_classes: 5\n",
    "- embedding_size: 128\n",
    "- fc2_size: 256\n",
    "\n",
    "The hypothesis here is that a moderate number of bins and a standard sigma value provide a good starting point for KDE. The dropout rate is set at a typical middle ground to prevent overfitting. An embedding size of 128 and fc2 size of 256 are assumed to provide enough capacity to capture complex relationships in the data without overly complexifying the model.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = \"UCC1to4_ExperimentA\"\n",
    "\n",
    "############################################\n",
    "# CONFIGS\n",
    "############################################\n",
    "\n",
    "MODEL_CONFIG_1 = ModelConfig(\n",
    "    num_bins = 10,\n",
    "    sigma = 0.1,\n",
    "    dropout_rate = 0.3,\n",
    "    num_classes = 5,\n",
    "    embedding_size = 128,\n",
    "    fc2_size = 256\n",
    ")\n",
    "\n",
    "model = UCCModel(**MODEL_CONFIG_1.__dict__)\n",
    "\n",
    "\n",
    "TRAIN_CONFIG_1 = TrainConfig(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    model_name=MODEL_NAME,\n",
    "    total_steps=5_000,\n",
    "    eval_interval=100,\n",
    "    ucc_loss_weight=0.5,\n",
    "    model_dir=\"../models\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer = Trainer(**TRAIN_CONFIG_1.__dict__)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb439d7a773801",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-11T16:30:39.351905Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENT CARD \n",
    "\n",
    "Config B\n",
    "- num_bins: 20\n",
    "- sigma : 0.05\n",
    "- dropout_rate: 0.5\n",
    "- num_classes: 5\n",
    "- embedding_size: 256\n",
    "- fc2_size: 128\n",
    "\n",
    "Doubling the number of bins might capture more nuances in data distribution, and halving sigma could provide finer estimation. A higher dropout rate is chosen to combat potential overfitting due to the increased complexity from more bins. The larger embedding size is to capture more detailed features, while a smaller fc2 size is to test if a bottleneck improves generalization.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = \"UCC1to4_ExperimentB\"\n",
    "\n",
    "MODEL_CONFIG_1 = ModelConfig(\n",
    "    num_bins = 20,\n",
    "    sigma = 0.05,\n",
    "    dropout_rate = 0.5,\n",
    "    num_classes = 5,\n",
    "    embedding_size = 256,\n",
    "    fc2_size = 128\n",
    ")\n",
    "\n",
    "model = UCCModel(**MODEL_CONFIG_1.__dict__)\n",
    "\n",
    "TRAIN_CONFIG_1 = TrainConfig(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    model_name=MODEL_NAME,\n",
    "    total_steps=5_000,\n",
    "    eval_interval=100,\n",
    "    ucc_loss_weight=0.5,\n",
    "    model_dir=\"../models\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer = Trainer(**TRAIN_CONFIG_1.__dict__)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3013cc7465e73",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-11T16:30:39.353029Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EXPERIMENT CARD \n",
    "\n",
    "Config C\n",
    "- num_bins: 5\n",
    "- sigma : 0.2\n",
    "- dropout_rate: 0.5\n",
    "- num_classes: 5\n",
    "- embedding_size: 64\n",
    "- fc2_size: 512\n",
    "\n",
    "With fewer bins and a larger sigma, the hypothesis is that the model might generalize better by avoiding capturing noise in the data distribution. A lower dropout rate is tested due to the simpler model. A smaller embedding is to see if a more compact representation suffices, while a larger fc2 size is to see if it allows for better classification boundaries.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = \"UCC1to4_ExperimentC\"\n",
    "\n",
    "MODEL_CONFIG_1 = ModelConfig(\n",
    "    num_bins = 5,\n",
    "    sigma = 0.2,\n",
    "    dropout_rate = 0.5,\n",
    "    num_classes = 5,\n",
    "    embedding_size = 64,\n",
    "    fc2_size = 512\n",
    ")\n",
    "model = UCCModel(**MODEL_CONFIG_1.__dict__)\n",
    "\n",
    "\n",
    "TRAIN_CONFIG_1 = TrainConfig(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    model_name=MODEL_NAME,\n",
    "    total_steps=5_000,\n",
    "    eval_interval=100,\n",
    "    ucc_loss_weight=0.5,\n",
    "    model_dir=\"../models\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer = Trainer(**TRAIN_CONFIG_1.__dict__)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af5bd60b0c511c05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Run_UCC1to4\"\n",
    "# MODEL_NAME = \"Run_UCC2to4_alpha1\"\n",
    "# MODEL_NAME = \"Run_UCC1to4\"\n",
    "# MODEL_NAME = \"Run_UCC2to4_alpha1\"\n",
    "PATH = \"../models/\"\n",
    "\n",
    "transforms = {\n",
    "    'random_horizontal_flip': lambda img: TF.hflip(img) if random.random() > 0.5 else img,\n",
    "    'normalize': lambda img: TF.normalize(img, mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "}\n",
    "\n",
    "DATA_CONFIG_1 = DataConfig(\n",
    "    npz_path_ = PATH,\n",
    "    lower_ucc = 1,\n",
    "    upper_ucc = 4,\n",
    "    bag_size = 20,\n",
    "    bag_fraction = 0.9,\n",
    "    batch_size = 10,\n",
    "    transform = transforms\n",
    ")\n",
    "\n",
    "dataloaders = create_dataloaders(**DATA_CONFIG_1.__dict__)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "MODEL_CONFIG_1 = ModelConfig(\n",
    "    num_bins = 10,\n",
    "    sigma = 0.1,\n",
    "    dropout_rate = 0.3,\n",
    "    num_classes = 5,\n",
    "    embedding_size = 64,\n",
    "    fc2_size = 512\n",
    ")\n",
    "model = UCCModel(**MODEL_CONFIG_1.__dict__)\n",
    "\n",
    "TRAIN_CONFIG_1 = TrainConfig(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    model_name=MODEL_NAME,\n",
    "    total_steps=100_000,\n",
    "    eval_interval=100,\n",
    "    ucc_loss_weight=0.5,\n",
    "    model_dir=\"../models\",\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer = Trainer(**TRAIN_CONFIG_1.__dict__)\n",
    "trainer.train()\n",
    "torch.save(model, PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4582a3a40039d3b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Eval"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30504b224da7ad13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Run_UCC1to4\"\n",
    "# MODEL_NAME = \"Run_UCC2to4_alpha1\"\n",
    "# MODEL_NAME = \"Run_UCC1to4\"\n",
    "# MODEL_NAME = \"Run_UCC2to4_alpha1\"\n",
    "\n",
    "PATH = \"../models/\" +  MODEL_NAME + \".pth\"\n",
    "load_model = torch.load(PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ab98f71ae6d6c0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ucc_acc = 0.342\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# UCC ACC\n",
    "############################################\n",
    "\n",
    "TEST_SIZE = 1000\n",
    "load_model.eval()\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_samples, batch_labels in dataloaders['test']:\n",
    "        output, _ = load_model(batch_samples)\n",
    "        if torch.argmax(output) == torch.tensor(batch_labels):\n",
    "            correct += 1\n",
    "print(\"ucc_acc = {}\".format(correct/TEST_SIZE))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T07:35:06.033776Z",
     "start_time": "2023-11-12T07:35:06.014607Z"
    }
   },
   "id": "603811f1824fbd18"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.108\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# CLUSTERING ACC\n",
    "############################################\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "\n",
    "# Load Data\n",
    "splitted_dataset = np.load(\"../data/Splitted CIFAR10.npz\")\n",
    "x_test = splitted_dataset['x_test'] / 255\n",
    "labels = splitted_dataset['y_test']\n",
    "x_test = torch.from_numpy(x_test)\n",
    "x_test = torch.transpose(x_test, 1, 3)\n",
    "transform = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "x_test = transform(x_test)\n",
    "x_test = x_test.type(torch.FloatTensor)\n",
    "\n",
    "# Eval\n",
    "model.eval()\n",
    "X = model.extract_features(x_test)\n",
    "X = X.detach().numpy()\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(X)\n",
    "predicted_labels = kmeans.labels_\n",
    "labels = labels.flatten()\n",
    "print(completeness_score(labels, predicted_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T07:38:46.246994Z",
     "start_time": "2023-11-12T07:38:46.219677Z"
    }
   },
   "id": "5c99049f0e2c8258"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
